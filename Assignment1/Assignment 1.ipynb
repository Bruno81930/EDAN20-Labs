{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.2846093167673765e-06\n",
      "{'bannlyst.txt': {'bannlyst.txt': 0.0, 'gosta.txt': 0.005229877077878004, 'herrgard.txt': 0.0012990047699401013, 'jerusalem.txt': 0.007318172253124071, 'kejsaren.txt': 0.0021458005452060277, 'marbacka.txt': 0.005096498280768068, 'nils.txt': 0.005343494386428176, 'osynliga.txt': 0.0059846289209750676, 'troll.txt': 0.007336242553428816}, 'gosta.txt': {'bannlyst.txt': 0.005229877077878004, 'gosta.txt': 0.0, 'herrgard.txt': 0.015142549355563969, 'jerusalem.txt': 0.008540109292371853, 'kejsaren.txt': 0.0065098346457967485, 'marbacka.txt': 0.02856110652389178, 'nils.txt': 0.025006368728038183, 'osynliga.txt': 0.05574757215207852, 'troll.txt': 0.032494044336534515}, 'herrgard.txt': {'bannlyst.txt': 0.0012990047699401013, 'gosta.txt': 0.015142549355563969, 'herrgard.txt': 0.0, 'jerusalem.txt': 0.007621512812700546, 'kejsaren.txt': 0.0008924889218526751, 'marbacka.txt': 0.011697992749605354, 'nils.txt': 0.014146983656255958, 'osynliga.txt': 0.02125636466641977, 'troll.txt': 0.00398629847308823}, 'jerusalem.txt': {'bannlyst.txt': 0.007318172253124071, 'gosta.txt': 0.008540109292371853, 'herrgard.txt': 0.007621512812700546, 'jerusalem.txt': 0.0, 'kejsaren.txt': 0.0020572043011912126, 'marbacka.txt': 0.012904030052990484, 'nils.txt': 0.013089780334137376, 'osynliga.txt': 0.041844060584734076, 'troll.txt': 0.0070637016049891945}, 'kejsaren.txt': {'bannlyst.txt': 0.0021458005452060277, 'gosta.txt': 0.0065098346457967485, 'herrgard.txt': 0.0008924889218526751, 'jerusalem.txt': 0.0020572043011912126, 'kejsaren.txt': 0.0, 'marbacka.txt': 0.04455800424262422, 'nils.txt': 0.004374366320021482, 'osynliga.txt': 0.005494345280277942, 'troll.txt': 0.08831263444615263}, 'marbacka.txt': {'bannlyst.txt': 0.005096498280768068, 'gosta.txt': 0.02856110652389178, 'herrgard.txt': 0.011697992749605354, 'jerusalem.txt': 0.012904030052990484, 'kejsaren.txt': 0.04455800424262422, 'marbacka.txt': 0.0, 'nils.txt': 0.04021456502051885, 'osynliga.txt': 0.0421062692429276, 'troll.txt': 0.023648688283162012}, 'nils.txt': {'bannlyst.txt': 0.005343494386428176, 'gosta.txt': 0.025006368728038183, 'herrgard.txt': 0.014146983656255958, 'jerusalem.txt': 0.013089780334137376, 'kejsaren.txt': 0.004374366320021482, 'marbacka.txt': 0.04021456502051885, 'nils.txt': 0.0, 'osynliga.txt': 0.03212848463669879, 'troll.txt': 0.01938707280520491}, 'osynliga.txt': {'bannlyst.txt': 0.0059846289209750676, 'gosta.txt': 0.05574757215207852, 'herrgard.txt': 0.02125636466641977, 'jerusalem.txt': 0.041844060584734076, 'kejsaren.txt': 0.005494345280277942, 'marbacka.txt': 0.0421062692429276, 'nils.txt': 0.03212848463669879, 'osynliga.txt': 0.0, 'troll.txt': 0.02826612301544059}, 'troll.txt': {'bannlyst.txt': 0.007336242553428816, 'gosta.txt': 0.032494044336534515, 'herrgard.txt': 0.00398629847308823, 'jerusalem.txt': 0.0070637016049891945, 'kejsaren.txt': 0.08831263444615263, 'marbacka.txt': 0.023648688283162012, 'nils.txt': 0.01938707280520491, 'osynliga.txt': 0.02826612301544059, 'troll.txt': 0.0}}\n",
      "\n",
      "\n",
      "0.000000|\n",
      "0.005230|\n",
      "0.001299|\n",
      "0.007318|\n",
      "0.002146|\n",
      "0.005096|\n",
      "0.005343|\n",
      "0.005985|\n",
      "0.007336|\n",
      "\n",
      "\n",
      "0.005230|\n",
      "0.000000|\n",
      "0.015143|\n",
      "0.008540|\n",
      "0.006510|\n",
      "0.028561|\n",
      "0.025006|\n",
      "0.055748|\n",
      "0.032494|\n",
      "\n",
      "\n",
      "0.001299|\n",
      "0.015143|\n",
      "0.000000|\n",
      "0.007622|\n",
      "0.000892|\n",
      "0.011698|\n",
      "0.014147|\n",
      "0.021256|\n",
      "0.003986|\n",
      "\n",
      "\n",
      "0.007318|\n",
      "0.008540|\n",
      "0.007622|\n",
      "0.000000|\n",
      "0.002057|\n",
      "0.012904|\n",
      "0.013090|\n",
      "0.041844|\n",
      "0.007064|\n",
      "\n",
      "\n",
      "0.002146|\n",
      "0.006510|\n",
      "0.000892|\n",
      "0.002057|\n",
      "0.000000|\n",
      "0.044558|\n",
      "0.004374|\n",
      "0.005494|\n",
      "0.088313|\n",
      "\n",
      "\n",
      "0.005096|\n",
      "0.028561|\n",
      "0.011698|\n",
      "0.012904|\n",
      "0.044558|\n",
      "0.000000|\n",
      "0.040215|\n",
      "0.042106|\n",
      "0.023649|\n",
      "\n",
      "\n",
      "0.005343|\n",
      "0.025006|\n",
      "0.014147|\n",
      "0.013090|\n",
      "0.004374|\n",
      "0.040215|\n",
      "0.000000|\n",
      "0.032128|\n",
      "0.019387|\n",
      "\n",
      "\n",
      "0.005985|\n",
      "0.055748|\n",
      "0.021256|\n",
      "0.041844|\n",
      "0.005494|\n",
      "0.042106|\n",
      "0.032128|\n",
      "0.000000|\n",
      "0.028266|\n",
      "\n",
      "\n",
      "0.007336|\n",
      "0.032494|\n",
      "0.003986|\n",
      "0.007064|\n",
      "0.088313|\n",
      "0.023649|\n",
      "0.019387|\n",
      "0.028266|\n",
      "0.000000|\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import regex as re\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "def get_documents(dir, suffix):\n",
    "            files = []\n",
    "            for file in os.listdir(dir):\n",
    "                if file.endswith(suffix):\n",
    "                    files.append(file)\n",
    "            return files\n",
    "\n",
    "def get_index(folder, documents):\n",
    "    index = dict()\n",
    "    for document in documents:\n",
    "        with open(os.path.join(folder, document)) as open_document:\n",
    "            match_list = list(re.finditer(\"\\p{Latin}+\", open_document.read()))\n",
    "\n",
    "        for match in match_list:\n",
    "            match_word = match.group(0).lower()\n",
    "            match_pos = match.span(0)[0]\n",
    "            if match_word not in index:\n",
    "                index[match_word] = dict()\n",
    "            if document not in index[match_word]:\n",
    "                index[match_word][document] = list()\n",
    "            index[match_word][document].append(match_pos)\n",
    "\n",
    "    pickle.dump(index, open('master_index.idx', \"wb\"))\n",
    "    return index\n",
    "\n",
    "\n",
    "def get_total_number_words_in(document):\n",
    "    return len(re.findall('\\p{Latin}+', open('Selma/' + document).read().lower()))\n",
    "\n",
    "\n",
    "def term_frequency(term, document, document_number_words, index):\n",
    "    words = document_number_words[document]\n",
    "    try:\n",
    "        return len(index[term][document])/words\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def inverse_document_frequency(term, documents, index):\n",
    "    document_count = 0\n",
    "    for document in documents:\n",
    "        try:\n",
    "            index[term][document]\n",
    "        except:\n",
    "            continue\n",
    "        document_count += 1\n",
    "    if document_count == 0:\n",
    "        return 0\n",
    "    return math.log(len(documents)/(document_count),10)\n",
    "\n",
    "def tf_idf(documents, index):\n",
    "    tf_idf = dict()\n",
    "    document_number_words = dict()\n",
    "    \n",
    "    for document in documents:\n",
    "        document_number_words[document] = get_total_number_words_in(document)\n",
    "\n",
    "    for document in documents:\n",
    "        tf_idf[document] = dict()\n",
    "\n",
    "    for term in index:\n",
    "        for document in documents:\n",
    "            tf_idf[document][term] = term_frequency(term, document, document_number_words, index) * inverse_document_frequency(term, documents, index)\n",
    "    return tf_idf\n",
    "\n",
    "def compare_documents(documents, index, tf_idf):\n",
    "    norm = dict()\n",
    "    cos_sim = dict()\n",
    "    \n",
    "    for document_1 in documents:\n",
    "        cos_sim[document_1] = dict()\n",
    "        for document_2 in documents:\n",
    "            cos_sim[document_1][document_2] = 0\n",
    "    \n",
    "    for document in documents:\n",
    "        ins_sqr = 0\n",
    "        for term in index:\n",
    "            ins_sqr += math.pow(tf_idf[document][term],2)\n",
    "        norm[document] = math.sqrt(ins_sqr)\n",
    "\n",
    "    for term in index:\n",
    "        for document_1 in documents:\n",
    "            for document_2 in documents:\n",
    "                if(document_1 == document_2):\n",
    "                    continue\n",
    "                cos_sim[document_1][document_2] += tf_idf[document_1][term] * tf_idf[document_2][term]\n",
    "\n",
    "    for document_1 in documents:\n",
    "        for document_2 in documents:\n",
    "            cos_sim[document_1][document_2] /= (norm[document_1]*norm[document_2])\n",
    "\n",
    "    return cos_sim\n",
    "\n",
    "documents = get_documents(\"Selma\", \"txt\")\n",
    "index = get_index('Selma', documents)\n",
    "tf_idf = tf_idf(documents, index)\n",
    "print(tf_idf[\"bannlyst.txt\"][\"et\"])\n",
    "cos_sim = compare_documents(documents, index, tf_idf)\n",
    "print(cos_sim)\n",
    "\n",
    "for document in cos_sim:\n",
    "    print(\"\\n\")\n",
    "    for second_doc in cos_sim[document]:\n",
    "        print(\"{0:.6f}\".format(cos_sim[document][second_doc]) + \"|\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
